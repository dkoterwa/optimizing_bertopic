{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:44.422101Z","iopub.status.busy":"2024-01-11T11:56:44.421125Z","iopub.status.idle":"2024-01-11T11:56:48.128214Z","shell.execute_reply":"2024-01-11T11:56:48.126745Z","shell.execute_reply.started":"2024-01-11T11:56:44.422061Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel\n","import pickle\n","from torch.utils.data import DataLoader, Dataset\n","import torch\n","import numpy as np\n","import pandas as pd\n","import glob\n","from tqdm import tqdm\n","import gc"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:48.131646Z","iopub.status.busy":"2024-01-11T11:56:48.130857Z","iopub.status.idle":"2024-01-11T11:56:48.139906Z","shell.execute_reply":"2024-01-11T11:56:48.138565Z","shell.execute_reply.started":"2024-01-11T11:56:48.131595Z"},"trusted":true},"outputs":[],"source":["class StringDataset(Dataset):\n","    def __init__(self, strings):\n","        self.strings = strings\n","\n","    def __len__(self):\n","        return len(self.strings)\n","\n","    def __getitem__(self, idx):\n","        return self.strings[idx]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:48.142741Z","iopub.status.busy":"2024-01-11T11:56:48.142241Z","iopub.status.idle":"2024-01-11T11:56:48.163544Z","shell.execute_reply":"2024-01-11T11:56:48.161621Z","shell.execute_reply.started":"2024-01-11T11:56:48.142700Z"},"trusted":true},"outputs":[],"source":["class Pooling:\n","    def __init__(self, pooling_type):\n","        self.pooling_type = pooling_type\n","\n","    def __call__(self, hidden_states, layer_number, attention_mask=None):\n","        if self.pooling_type == \"cls\":\n","            return hidden_states[layer_number][:, 0, :]\n","        elif self.pooling_type == \"mean\":\n","            token_embeddings = hidden_states[\n","                layer_number\n","            ]  # First element of model_output contains all token embeddings\n","            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","            return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n","                input_mask_expanded.sum(1), min=1e-9\n","            )\n","        elif self.pooling_type == \"max\":\n","            token_embeddings = hidden_states[layer_number]\n","            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","            token_embeddings[input_mask_expanded == 0] = -1e9  # Set padding tokens to large negative value\n","            max_embeddings = torch.max(token_embeddings, 1)[0]\n","            return max_embeddings\n","        else:\n","            raise ValueError(\"Wrong pooling method provided in the Pooler initialization\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:48.168422Z","iopub.status.busy":"2024-01-11T11:56:48.167168Z","iopub.status.idle":"2024-01-11T11:56:48.189932Z","shell.execute_reply":"2024-01-11T11:56:48.187896Z","shell.execute_reply.started":"2024-01-11T11:56:48.168363Z"},"trusted":true},"outputs":[],"source":["class EmbeddingsRetriever:\n","    def __init__(self, embedding_model, tokenizer):\n","        self.embedding_model = embedding_model\n","        self.tokenizer = tokenizer\n","        self.functions = [self.get_embedding_layer_output, \n","                          self.get_embedding_last_hidden_layer, \n","                          self.get_embedding_sum_all_layers, \n","                          self.get_embedding_second_last_layer, \n","                          self.get_embedding_sum_last_four_layers, \n","                          self.get_embedding_concat_last_four_layers]\n","\n","    def tokenize_and_produce_model_output(self, data):\n","        encoded_input = self.tokenizer(data, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n","        self.attention_mask = encoded_input[\"attention_mask\"]\n","        with torch.no_grad():\n","            self.model_output = self.embedding_model(**encoded_input)\n","\n","    def get_embedding_from_layer(self, layer_number, pooling=\"cls\"):\n","        hidden_states = self.model_output[\"hidden_states\"]\n","        if pooling == \"cls\":\n","            pooler = Pooling(\"cls\")\n","            return pooler(hidden_states, layer_number)\n","\n","        elif pooling == \"mean\":\n","            assert self.attention_mask != None, \"Please provide attention mask if you are using mean pooling\"\n","            pooler = Pooling(\"mean\")\n","            return pooler(hidden_states, layer_number, self.attention_mask)\n","\n","        elif pooling == \"max\":\n","            assert self.attention_mask != None, \"Please provide attention mask if you are using max pooling\"\n","            pooler = Pooling(\"max\")\n","            return pooler(hidden_states, layer_number, self.attention_mask)\n","        else:\n","            raise ValueError(\"Wrong pooling method provided in the function call\")\n","\n","    def get_embedding_layer_output(self, pooling=\"cls\"):\n","        return self.get_embedding_from_layer(0, pooling).numpy()\n","\n","    def get_embedding_last_hidden_layer(self, pooling=\"cls\"):\n","        return self.get_embedding_from_layer(-1, pooling).numpy()\n","\n","    def get_embedding_sum_all_layers(self, pooling=\"cls\"):\n","        outputs = []\n","        for layer in range(13):\n","            output = self.get_embedding_from_layer(layer, pooling)\n","            outputs.append(output.numpy())\n","        return sum(outputs)\n","\n","    def get_embedding_second_last_layer(self, pooling=\"cls\"):\n","        return self.get_embedding_from_layer(-2, pooling).numpy()\n","\n","    def get_embedding_sum_last_four_layers(self, pooling=\"cls\"):\n","        outputs = []\n","        layers = [-4, -3, -2, -1]\n","        for layer in layers:\n","            output = self.get_embedding_from_layer(layer, pooling)\n","            outputs.append(output.numpy())\n","        return sum(outputs)\n","\n","    def get_embedding_concat_last_four_layers(self, pooling=\"cls\"):\n","        outputs = []\n","        layers = [-4, -3, -2, -1]\n","        for layer in layers:\n","            output = self.get_embedding_from_layer(layer, pooling)\n","            outputs.append(output)\n","        return torch.cat(outputs, dim=-1).numpy()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:48.192448Z","iopub.status.busy":"2024-01-11T11:56:48.192028Z","iopub.status.idle":"2024-01-11T11:56:48.315133Z","shell.execute_reply":"2024-01-11T11:56:48.313929Z","shell.execute_reply.started":"2024-01-11T11:56:48.192413Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv(\"/kaggle/input/corpus-trump/corpus_trump.tsv\", sep=\"\\t\", header=None)\n","texts = data.iloc[:, 0].tolist()\n","del data"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:49.912097Z","iopub.status.busy":"2024-01-11T11:56:49.911567Z","iopub.status.idle":"2024-01-11T11:56:49.919392Z","shell.execute_reply":"2024-01-11T11:56:49.918114Z","shell.execute_reply.started":"2024-01-11T11:56:49.912055Z"},"trusted":true},"outputs":[],"source":["texts_part_1 = texts[:20000]\n","texts_part_2 = texts[20000:]"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:50.500488Z","iopub.status.busy":"2024-01-11T11:56:50.499993Z","iopub.status.idle":"2024-01-11T11:56:50.506597Z","shell.execute_reply":"2024-01-11T11:56:50.505034Z","shell.execute_reply.started":"2024-01-11T11:56:50.500448Z"},"trusted":true},"outputs":[],"source":["dataset_first = StringDataset(texts_part_1)\n","dataloader_first = DataLoader(dataset_first, batch_size=64)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:50.936090Z","iopub.status.busy":"2024-01-11T11:56:50.935618Z","iopub.status.idle":"2024-01-11T11:56:50.942642Z","shell.execute_reply":"2024-01-11T11:56:50.941129Z","shell.execute_reply.started":"2024-01-11T11:56:50.936053Z"},"trusted":true},"outputs":[],"source":["dataset_second = StringDataset(texts_part_2)\n","dataloader_second = DataLoader(dataset_second, batch_size=64)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:52.868351Z","iopub.status.busy":"2024-01-11T11:56:52.867706Z","iopub.status.idle":"2024-01-11T11:56:53.080573Z","shell.execute_reply":"2024-01-11T11:56:53.079394Z","shell.execute_reply.started":"2024-01-11T11:56:52.868298Z"},"trusted":true},"outputs":[{"data":{"text/plain":["60"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["del texts_part_1\n","del texts_part_2\n","del texts\n","gc.collect()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:56:53.515630Z","iopub.status.busy":"2024-01-11T11:56:53.514624Z","iopub.status.idle":"2024-01-11T11:56:54.751204Z","shell.execute_reply":"2024-01-11T11:56:54.749840Z","shell.execute_reply.started":"2024-01-11T11:56:53.515582Z"},"trusted":true},"outputs":[],"source":["model_name = \"sentence-transformers/all-MiniLM-L12-v2\"  # Replace with the appropriate model name\n","model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","embedder = EmbeddingsRetriever(model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["poolings = [\"mean\", \"cls\", \"max\"]\n","embeddings_dict = {function.__name__ + \"_\"  + pooling: [] for function in embedder.functions for pooling in poolings}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for batch in tqdm(dataloader_first):\n","    embedder.tokenize_and_produce_model_output(batch)\n","    for function in embedder.functions:\n","        for pooling in poolings:\n","            embedding = function(pooling=pooling)\n","            embeddings_dict[function.__name__ + \"_\" + pooling].extend(embedding)\n","            del embedding\n","            gc.collect()\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(embeddings_dict[\"get_embedding_layer_output_mean\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.save('embeddings_trump_part1.npy', embeddings_dict) "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:57:02.058899Z","iopub.status.busy":"2024-01-11T11:57:02.057260Z","iopub.status.idle":"2024-01-11T11:57:02.064969Z","shell.execute_reply":"2024-01-11T11:57:02.063877Z","shell.execute_reply.started":"2024-01-11T11:57:02.058845Z"},"trusted":true},"outputs":[],"source":["poolings = [\"mean\", \"cls\", \"max\"]\n","embeddings_dict = {function.__name__ + \"_\"  + pooling: [] for function in embedder.functions for pooling in poolings}"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T11:57:04.793618Z","iopub.status.busy":"2024-01-11T11:57:04.792000Z","iopub.status.idle":"2024-01-11T12:58:44.583737Z","shell.execute_reply":"2024-01-11T12:58:44.582294Z","shell.execute_reply.started":"2024-01-11T11:57:04.793557Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 379/379 [1:01:39<00:00,  9.76s/it]\n"]}],"source":["for batch in tqdm(dataloader_second):\n","    embedder.tokenize_and_produce_model_output(batch)\n","    for function in embedder.functions:\n","        for pooling in poolings:\n","            embedding = function(pooling=pooling)\n","            embeddings_dict[function.__name__ + \"_\" + pooling].extend(embedding)\n","            del embedding\n","            gc.collect()\n","  "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T12:58:44.588017Z","iopub.status.busy":"2024-01-11T12:58:44.586731Z","iopub.status.idle":"2024-01-11T12:58:44.598298Z","shell.execute_reply":"2024-01-11T12:58:44.597077Z","shell.execute_reply.started":"2024-01-11T12:58:44.587963Z"},"trusted":true},"outputs":[{"data":{"text/plain":["24252"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["len(embeddings_dict[\"get_embedding_layer_output_mean\"])"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-01-11T12:58:44.600113Z","iopub.status.busy":"2024-01-11T12:58:44.599734Z","iopub.status.idle":"2024-01-11T12:58:54.302362Z","shell.execute_reply":"2024-01-11T12:58:54.301068Z","shell.execute_reply.started":"2024-01-11T12:58:44.600083Z"},"trusted":true},"outputs":[],"source":["np.save('embeddings_trump_part2.npy', embeddings_dict) "]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4288043,"sourceId":7378802,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
